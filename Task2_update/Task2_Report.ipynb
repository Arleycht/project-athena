{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <h1><center>Task 2 Report</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment\n",
    "\n",
    "Much like Task 1, the goal is to generate adverserial examples and evaluate them on the Undefended Model, the Vanilla Athena, and the PGD-ADT. The difference with task 1 comes from the context that the attacks are given. In task 1, it is given zero knowledge about the model. For task 2, the attack is given knowledge about the model and its defenses, a white-box attack.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimental Settings\n",
    "\n",
    "1. Use the same subsample from Task 1.\n",
    "2. Load a pool of weak defenses into an ensemble. In this case, 5 weak defenses are loaded.\n",
    "3. Generate the adverserial examples with the Vanilla Athena as the target.\n",
    "4. Save the results of the generation(includes sample images of the perturbation)\n",
    "5. Evaluate the generated AEs on the undefended model, the Vanilla Athena with the 5 WDs pooled in step two, and the PGD-ADT.\n",
    "6. Save the evaluation results in JSON format.\n",
    "\n",
    "## Elaboration\n",
    "\n",
    "For this task, to keep things orderly, we copied the same subsamples from Task 1 to Task 2. This also makes comparison between the two tasks much more accurate as they are using the same subsamples. \n",
    "\n",
    "* The subsamples can be found under /Task2_update/data/subsample/subsamples-mnist-ratio_0.05-590500.359/\n",
    "* The sublabels can be found under /Task2_update/data/subsample/sublabels-mnist-ratio_0.05-590500.359/\n",
    "\n",
    "After getting the subsamples, we loaded a pool of 5 weak defenses(WD) to the Vanilla Athena. These are all arbitrarily selected. The team made sure that the WDs are diverse. Initially, the team wanted to load a pool of 15 weak defenses into the ensemble but due to the computational costs that loading additional weak defenses add, we decided to stick with the first 5 weak defenses to be loaded. This ensemble is then set as the target for generating the adverserial examples. By doing this, the attack gets all the information about the model it is attacking. \n",
    "\n",
    "The weak defenses selected are:\n",
    "\n",
    "* _model-mnist-cnn-rotate90.h5_\n",
    "* _model-mnist-cnn-shift_left.h5_\n",
    "* _model-mnist-cnn-flip_horizontal.h5_\n",
    "* _model-mnist-cnn-affine_vertical_compress.h5_\n",
    "* _model-mnist-cnn-morph_erosion.h5_\n",
    "\n",
    "After setting the target, the team generated adverserial examples using the Fast Gradient Sign Method, and the Project Gradient Descent attack. Each attack will have 5 different epsilon values as the parameter to generate the adverserial example. For each epsilon value, there will be 2 variants. One will have be extended with the Expectation over Transformation(EOT) algorithm, while the other will not. This will help determine how EOT affects the attack's potency. With these, the total amount of variants will be 20. \n",
    "\n",
    "The configurations of the attacks can be found in:\n",
    "\n",
    "* _/Task2_update/configs/attack-wb-mnist.json_\n",
    "* _/Task2_update/configs/attack-wb-mnist.json_\n",
    "\n",
    "The generated adverserial examples can be found under _/Task2_update/data/adversary_examples/_\n",
    "\n",
    "Afterwards, the generated AEs are evaluated on the undefended model, the Vanilla Athena with the same 5 WDs that the team generated AEs on, and the PGD-ADT.\n",
    "\n",
    "These can be found under _/models/cnn/_\n",
    "\n",
    "The results of the evaluation are found under _/Task2_update/results/ae_evaluation_results.json/_\n",
    "\n",
    "If one is to read the Task 1 Report, the weak defenses selected in this Task are the same as Task 1. This is decided so that the team can compare a zero-knowledge attack versus a white-box attack."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <h1><center>FGSM Adverserial Example Images and Error Rates</center></h1>\n",
    "\n",
    "| Parameter | FGSM EOT OFF Image |FGSM EOT ON Image |\n",
    "| :---: | :---: | :---: |\n",
    "|<b>eps0.1</b> | <img src=\"images/FGSM_eps0.1-0-EOT_OFF.png\">  <img src=\"images/FGSM_eps0.1-1-EOT_OFF.png\"> |<img src=\"images/FGSM_eps0.1-0-EOT_ON.png\">  <img src=\"images/FGSM_eps0.1-1-EOT_ON.png\">  |\n",
    "|<b>eps0.15</b> | <img src=\"images/FGSM_eps0.15-0-EOT_OFF.png\"> <img src=\"images/FGSM_eps0.15-1-EOT_OFF.png\"> | <img src=\"images/FGSM_eps0.15-0-EOT_ON.png\"> <img src=\"images/FGSM_eps0.15-1-EOT_ON.png\"> |\n",
    "|<b>eps0.2</b>| <img src=\"images/FGSM_eps0.2-0-EOT_OFF.png\"> <img src=\"images/FGSM_eps0.2-1-EOT_OFF.png\"> | <img src=\"images/FGSM_eps0.2-0-EOT_ON.png\"> <img src=\"images/FGSM_eps0.2-1-EOT_ON.png\"> |\n",
    "|<b>eps0.23</b>| <img src=\"images/FGSM_eps0.23-0-EOT_OFF.png\"> <img src=\"images/FGSM_eps0.23-1-EOT_OFF.png\"> | <img src=\"images/FGSM_eps0.23-0-EOT_ON.png\"> <img src=\"images/FGSM_eps0.23-1-EOT_ON.png\"> |\n",
    "|<b>eps0.25</b> | <img src=\"images/FGSM_eps0.25-0-EOT_OFF.png\"> <img src=\"images/FGSM_eps0.25-1-EOT_OFF.png\"> | <img src=\"images/FGSM_eps0.25-0-EOT_ON.png\"> <img src=\"images/FGSM_eps0.25-1-EOT_ON.png\"> |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FGSM Evaluation Table\n",
    "\n",
    "## <h3><center>EOT:OFF</center></h3>\n",
    "| Epsilon Value | UM | Vanilla Athena | PGD-ADT |\n",
    "| :---: | :---: | :---: | :---: |\n",
    "| eps0.1| 0.020161290322580645 | 0.006048387096774193 | 0.006048387096774193 |\n",
    "| eps0.15| 0.03024193548387097 | 0.016129032258064516 | 0.010080645161290322 |\n",
    "| eps0.2| 0.07862903225806452 | 0.056451612903225805 | 0.024193548387096774 |\n",
    "| eps0.23| 0.1431451612903226 | 0.11290322580645161 | 0.036290322580645164 |\n",
    "| eps0.25| 0.19153225806451613 | 0.16129032258064516 | 0.046370967741935484 |\n",
    "\n",
    "## <h3><center>EOT:ON</center></h3>\n",
    "| Epsilon Value | UM | Vanilla Athena | PGD-ADT |\n",
    "| :---: | :---: | :---: | :---: |\n",
    "| eps0.1| 0.018145161290322582 | 0.010080645161290322 | 0.004032258064516129 |\n",
    "| eps0.15| 0.04032258064516129  | 0.02217741935483871 | 0.006048387096774193 |\n",
    "| eps0.2| 0.06451612903225806 | 0.07661290322580645 |0.016129032258064516 |\n",
    "| eps0.23| 0.12298387096774194 | 0.1592741935483871 | 0.020161290322580645 |\n",
    "| eps0.25| 0.19959677419354838 | 0.21975806451612903 | 0.03024193548387097 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EOT ON vs OFF Analysis\n",
    "\n",
    "In Task 1, EOT has negatively affected the evaluation of the generated adverserial examples very heavily. By giving the model's information to the attacker, as per expectations, EOT makes the adverserial example more robust. In this case, in all evaluations in the Vanilla Athena which we gave information to the attacker to, the attack's potency is greatly enhanced in comparison to the adversary examples without EOT. However, it seems like other than the evaluation in the Vanilla Athena, the attack's potency is still weakened. The only exception to this is when the epsilon is at 0.25, the highest we tested, where in the evaluation for the undefended model, having EOT on is actually higher than having EOT off. If that trend follows throughout greater epsilon values, that means having EOT on for attacks with high epsilon values is stronger than without. Against defended models where the attack does not know the exact information, EOT weakens.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <h1><center>FGSM Evaluation Graph(Whitebox)</center></h1>\n",
    "\n",
    "| ZK Threat Model Graph | White-box Attack |\n",
    "| :---: | :---: |\n",
    "| <img src =\"../Task1_update/graphs/FGSM.png\"> | <img src =\"graphs/FGSM.png\"> |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zero-Knowledge Threat Model vs Optimization Based White-box Attack\n",
    "\n",
    "One thing that the team has noticed with this graph is that everything is a lot lower in the white-box attack than it is on the zero-knowledge threat model. This is to be expected as leaving a model undefended makes it very vulnerable to \n",
    "adverserial attacks. The biggest drop in the error rate comes from the evaluation of the undefended model with EOT off. In the zero-knowledge threat model, the error rate goes all the way up to 0.8. In the white-box attack, the highest the error rate got is 0.22 which is when the EOT is on and the epsilon is set to 0.25. In the topic of EOT being on,  based on this graph, it seems as though the error rate between the zero-knowledge threat model and the white-box attack is almost unchanged for evaluation with defenses put in. In the case of the model being evaluated is the same as the target, the error rate is actually higher in the white-box attack than it is when the target is undefended. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <h1><center>PGD Adverserial Example Images and Error Rates</center></h1>\n",
    "\n",
    "| Parameter | PGD EOT OFF Image | PGD EOT ON Image |\n",
    "| :---: | :---: | :---: | \n",
    "|<b>eps0.08</b> | <img src=\"images/PGD_eps0.08-0-EOT_OFF.png\"> <img src=\"images/PGD_eps0.08-1-EOT_OFF.png\"> |<img src=\"images/PGD_eps0.08-0-EOT_ON.png\"> <img src=\"images/PGD_eps0.08-1-EOT_ON.png\"> |\n",
    "|<b>eps0.12</b> | <img src=\"images/PGD_eps0.12-0-EOT_OFF.png\"> <img src=\"images/PGD_eps0.12-1-EOT_OFF.png\"> | <img src=\"images/PGD_eps0.12-0-EOT_ON.png\"> <img src=\"images/PGD_eps0.12-1-EOT_ON.png\"> |\n",
    "|<b>eps0.15</b> | <img src=\"images/PGD_eps0.15-0-EOT_OFF.png\"> <img src=\"images/PGD_eps0.15-1-EOT_OFF.png\"> |<img src=\"images/PGD_eps0.15-0-EOT_ON.png\"> <img src=\"images/PGD_eps0.15-1-EOT_ON.png\"> |\n",
    "|<b>eps0.17</b> | <img src=\"images/PGD_eps0.17-0-EOT_OFF.png\"> <img src=\"images/PGD_eps0.17-1-EOT_OFF.png\"> |<img src=\"images/PGD_eps0.17-0-EOT_ON.png\"> <img src=\"images/PGD_eps0.17-1-EOT_ON.png\"> |\n",
    "|<b>eps0.2</b> | <img src=\"images/PGD_eps0.2-0-EOT_OFF.png\"> <img src=\"images/PGD_eps0.2-1-EOT_OFF.png\"> | <img src=\"images/PGD_eps0.2-0-EOT_ON.png\"> <img src=\"images/PGD_eps0.2-1-EOT_ON.png\"> |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><center>PGD EOT:OFF</center></h3>\n",
    "\n",
    "| Epsilon Value | UM | Vanilla Athena | PGD-ADT |\n",
    "| :---: | :---: | :---: | :---: |\n",
    "| eps0.08| 0.008064516129032258 | 0.006048387096774193 | 0.004032258064516129 |\n",
    "| eps0.12| 0.024193548387096774 | 0.012096774193548387 | 0.006048387096774193 |\n",
    "| eps0.15| 0.034274193548387094 | 0.02217741935483871 | 0.008064516129032258 |\n",
    "| eps0.17| 0.038306451612903226 | 0.03225806451612903 | 0.014112903225806451 |\n",
    "| eps0.20| 0.06653225806451613 | 0.04032258064516129 | 0.016129032258064516 |\n",
    "\n",
    "<h3><center>PGD EOT:ON</center></h3>\n",
    "\n",
    "| Epsilon Value | UM | Vanilla Athena | PGD-ADT |\n",
    "| :---: | :---: | :---: | :---: |\n",
    "| eps0.08| 0.008064516129032258 | 0.008064516129032258 | 0.004032258064516129 |\n",
    "| eps0.12| 0.014112903225806451 | 0.010080645161290322 | 0.006048387096774193 |\n",
    "| eps0.15| 0.024193548387096774 | 0.020161290322580645 | 0.006048387096774193 |\n",
    "| eps0.17| 0.02620967741935484 | 0.03225806451612903 | 0.010080645161290322 |\n",
    "| eps0.20| 0.038306451612903226 | 0.06653225806451613 | 0.012096774193548387 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EOT ON vs OFF Analysis\n",
    "\n",
    "PGD follows the same trend as FGSM when it comes to the difference between EOT being on and EOT being off. However, there is an interesting thing that came up with PGD. In the epsilon value 0.08, the evaluation for the Vanilla Athena is higher when EOT is on than when it is off. However, for epsilon values 0.12 and 0.15, EOT off is actually greater by roughly 0.002 then they equalize back up at 0.17. In the final epsilon step that we tested(0.20), EOT on is back to being higher than EOT off. Again, if this trend continues, this suggests that EOT becomes more effective as the epsilon values get higher."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <h1><center>PGD Evaluation Graph(White-box)</center></h1>\n",
    "\n",
    "| ZK Threat Model Graph | White-box Attack |\n",
    "| :---: | :---: |\n",
    "| <img src =\"../Task1_update/graphs/PGD.png\"> | <img src =\"graphs/PGD.png\"> |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like in the graph for FGSM, PGD also suffers a huge drop in the error rate in the white-box attack evaluated on the undefended model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contribution: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Citation: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
